{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_HPE_GRP_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFiCg59UWrrmu4zi/dTS3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonalgan/DeepLearning/blob/main/Project_HPE_GRP_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtAwYQ9Uggno"
      },
      "source": [
        "load and read the  Pre-Processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXx-eyneALaj"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "#loading the data\r\n",
        "df=pd.read_csv('https://github.com/404S-retr0/HPE_Project_Grp-8/blob/main/Data_Wordlists.csv?raw=true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSnLynJbhANN"
      },
      "source": [
        "Defining Word2Vec "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDubymh3pY5U"
      },
      "source": [
        "#Creating dictionary of each language (English,Danish,Dutch,French,nGerman,Italian,Polish,Portuguese,Spanish,Swedish)\r\n",
        "word2int_eng = {} #93054 words\r\n",
        "for i in range(93056):\r\n",
        "  word2int_eng[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_dan = {} #96825 words\r\n",
        "for i in range(93056,189881):\r\n",
        "  word2int_dan[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_dut = {} #96698 words\r\n",
        "for i in range(189881,286579):\r\n",
        "  word2int_dut[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_fre = {} #95564 words\r\n",
        "for i in range(286579,382144):\r\n",
        "  word2int_fre[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_ger = {} #97447 words\r\n",
        "for i in range(382144,479592):\r\n",
        "  word2int_ger[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_ita = {} #96847 words\r\n",
        "for i in range(479592,576439):\r\n",
        "  word2int_ita[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_pol = {} #98181 words\r\n",
        "for i in range(576439,674620):\r\n",
        "  word2int_pol[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_por = {} #96429 words\r\n",
        "for i in range(674620,771049):\r\n",
        "  word2int_por[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_spa = {} #97058 words\r\n",
        "for i in range(771049,868107):\r\n",
        "  word2int_spa[df.WORDS[i]] = i\r\n",
        "\r\n",
        "word2int_swe = {} #96870 words\r\n",
        "for i in range(868107,964977):\r\n",
        "  word2int_swe[df.WORDS[i]] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1bQeQQ7pxYc"
      },
      "source": [
        "#Nesting of Dictionary \r\n",
        "word2int = {\r\n",
        "  1 : word2int_eng,    #English\r\n",
        "  2 : word2int_dan,    #Danish\r\n",
        "  3 : word2int_dut,    #Dutch\r\n",
        "  4 : word2int_fre,    #French\r\n",
        "  5 : word2int_ger,    #German\r\n",
        "  6 : word2int_ita,    #Italian\r\n",
        "  7 : word2int_pol,    #Polish\r\n",
        "  8 : word2int_por,    #Portuguese\r\n",
        "  9 : word2int_spa,    #Spanish\r\n",
        "  10 : word2int_swe    #Swedish\r\n",
        "}\r\n",
        "int2word = {}\r\n",
        "for i,word in enumerate(df['WORDS'].values):\r\n",
        "  int2word[i] = df.WORDS[i] \r\n",
        "\r\n",
        "df['int2word'] = int2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RJRwaRyygyl"
      },
      "source": [
        "Splitting Data into Train and Test sets (80:20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1hMx_ULrRYs",
        "outputId": "87339662-b85c-4fdb-abb4-e4ef72c263b4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "x,y=df['int2word'].values,df['LANGAUAGE_VECTOR'].values\r\n",
        "#Reshape your data using array.reshape(-1, 1) because of data has a single feature.\r\n",
        "x=x.reshape(-1,1)\r\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_test.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(771981, 1)\n",
            "(192996, 1)\n",
            "(771981,)\n",
            "(192996,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eRe9A0TrjOD",
        "outputId": "480fdbf6-5495-4b07-80c6-fee22952d69b"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "# Create KNN classifier Model and Fit the classifier to the data\r\n",
        "knn = KNeighborsClassifier()\r\n",
        "knn.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI6UHW62wUPN"
      },
      "source": [
        "Model Evaluation and trail run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHl_BzECrrXA",
        "outputId": "fe1afb0a-156b-471a-f236-da028565bb10"
      },
      "source": [
        "ac = \"Accuracy Score = {}\".format(knn.score(x_test, y_test))\r\n",
        "print(ac)\r\n",
        "tm=\"Testing the model\\nrandomw five words location:-\\n{}\\nPredection of which word belong to which language belong :-{}\".format(x_test[0:5],knn.predict(x_test)[0:5])\r\n",
        "print(tm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.9999844556363863\n",
            "Testing the model\n",
            "randomw five words location:-\n",
            "[[302556]\n",
            " [140769]\n",
            " [399592]\n",
            " [555380]\n",
            " [148898]]\n",
            "Predection of which word belong to which language belong :-[4 2 5 6 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2epPFb9tJV6"
      },
      "source": [
        "Saving the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sh2jH1ye669"
      },
      "source": [
        "import pickle\r\n",
        "File = open('LDPModel.pckl','wb')\r\n",
        "pickle.dump(knn,File)\r\n",
        "File.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3mLAm1tomJ"
      },
      "source": [
        "Defining text2list function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lyymlYbFRov"
      },
      "source": [
        "def text2list(text):\r\n",
        "  import string\r\n",
        "  import re\r\n",
        "  test_str=text\r\n",
        "  test_str = ''.join([i for i in test_str if not i.isdigit()]) \r\n",
        "  test_str=test_str.lower()\r\n",
        "  punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~+-=|`'''\r\n",
        "\r\n",
        "  for ele in test_str:\r\n",
        "    if ele in punc:\r\n",
        "      test_str = test_str.replace(ele, \"\")  \r\n",
        "\r\n",
        "  test_str_split=re.split('\\s+', test_str)\r\n",
        "  \r\n",
        "  if (test_str_split[0]==''):\r\n",
        "    test_str_split.remove('')\r\n",
        "  if (test_str_split[len(test_str_split)-1]==''):\r\n",
        "    test_str_split.remove('')\r\n",
        "\r\n",
        "  return test_str_split\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5jsUuB9tUX0"
      },
      "source": [
        "Loading the Model and defining lang_detect_in_percentage function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4N8XKiRFIP1"
      },
      "source": [
        "def lang_detect(text):\r\n",
        "  list_of_word=text2list(text)\r\n",
        "\r\n",
        "  import pickle\r\n",
        "  global LangDetectModel\r\n",
        "  LangDetectFile = open('LDPModel.pckl','rb')\r\n",
        "  LangDetectModel = pickle.load(LangDetectFile)\r\n",
        "  LangDetectFile.close();\r\n",
        "  \r\n",
        "  eng=0\r\n",
        "  dan=0\r\n",
        "  dut=0\r\n",
        "  fre=0\r\n",
        "  ger=0\r\n",
        "  ita=0\r\n",
        "  pol=0\r\n",
        "  por=0\r\n",
        "  spa=0\r\n",
        "  swe=0\r\n",
        "  unknown=0\r\n",
        "  for q in range(len(list_of_word)):\r\n",
        "    pos=[]\r\n",
        "    try:\r\n",
        "      for i in range(1,11):\r\n",
        "        p=word2int[i][list_of_word[q]]\r\n",
        "        pos.append(p)\r\n",
        "    except:\r\n",
        "      if (len(pos)==0):\r\n",
        "        unknown=1\r\n",
        "    else:\r\n",
        "      for j in range(len(pos)):\r\n",
        "        pre=LangDetectModel.predict(x)[pos[j]]\r\n",
        "        if (pre==1):\r\n",
        "          eng +=1\r\n",
        "        elif (pre==2):\r\n",
        "          dan +=1\r\n",
        "        elif (pre==3):\r\n",
        "          dut +=1\r\n",
        "        elif (pre==4):\r\n",
        "          fre +=1\r\n",
        "        elif (pre==5):\r\n",
        "          ger +=1\r\n",
        "        elif (pre==6):\r\n",
        "          ita +=1\r\n",
        "        elif (pre==7):\r\n",
        "          pol +=1\r\n",
        "        elif (pre==8):\r\n",
        "          por +=1\r\n",
        "        elif (pre==9):\r\n",
        "          spa +=1\r\n",
        "        elif (pre==10):\r\n",
        "          swe +=1\r\n",
        "        else:\r\n",
        "         None\r\n",
        "\r\n",
        "  total=eng+dan+dut+fre+ger+ita+pol+por+spa+swe+unknown\r\n",
        "  p_eng=eng/total\r\n",
        "  p_dan=dan/total\r\n",
        "  p_dut=dut/total\r\n",
        "  p_fre=fre/total\r\n",
        "  p_ger=ger/total\r\n",
        "  p_ita=ita/total\r\n",
        "  p_pol=pol/total\r\n",
        "  p_por=por/total\r\n",
        "  p_spa=spa/total\r\n",
        "  p_swe=swe/total\r\n",
        "  p_unk=unknown/total\r\n",
        "  report = \"Percentage Distribution\\nEnglish:-{}\\nDanish:-{}\\nDutch:-{}\\nFrench:-{}\\nGerman:-{}\\nItalian:-{}\\nPolish:-{}\\nPortuguese:-{}\\nSpanish:-{}\\nSwedish:-{}\\nUnknown:-{}\".format( p_eng,p_dan,p_dut,p_fre,p_ger,p_ita,p_pol,p_por,p_spa,p_swe,p_unk)\r\n",
        "  print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQrjx_i7fOuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca13ca4-4cd8-4cd6-c685-d3bb5b32d5ac"
      },
      "source": [
        "lang_detect('hello @amigo , m+y name is 007. wie gehts? Â¿necesitas ayuda?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage Distribution\n",
            "English:-0.0975609756097561\n",
            "Danish:-0.0975609756097561\n",
            "Dutch:-0.0975609756097561\n",
            "French:-0.0975609756097561\n",
            "German:-0.0975609756097561\n",
            "Italian:-0.0975609756097561\n",
            "Polish:-0.0975609756097561\n",
            "Portuguese:-0.0975609756097561\n",
            "Spanish:-0.0975609756097561\n",
            "Swedish:-0.0975609756097561\n",
            "Unknown:-0.024390243902439025\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}