{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Initialise the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1613152146210
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.20.0\n",
      "mlhpe2\teastus2\trghpe\teastus2\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "\n",
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Initialize an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1613152191847
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = 'langdetection'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create a Datastore/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndatastore_name='workspaceblobstore'\\ndatastore = Datastore.get(ws, datastore_name)\\n#Upload Data\\n\\nds = ws.get_default_datastore()\\n#ds.upload(src_dir='./src', target_path='dataset.csv', overwrite=True, show_progress=True)\\npaths=[(ds, 'dataset.csv')]\\npath='https://raw.githubusercontent.com/sonalgan/DeepLearning/master/dataset.csv'\\nlang_ds = Dataset.Tabular.from_delimited_files(path=path)\\n\\nds = ws.get_default_datastore()\\n#weather_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\\nprint(ds.datastore_type, ds.account_name, ds.container_name)\\nds.upload(src_dir='./src', target_path='langdataset.csv', overwrite=True, show_progress=True)\\n\\nlang_ds.take(3).to_pandas_dataframe()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core import Datastore, Dataset\n",
    "script_folder = os.path.join(os.getcwd(), \"AzureMLFramework\")\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "'''\n",
    "datastore_name='workspaceblobstore'\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "#Upload Data\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "#ds.upload(src_dir='./src', target_path='dataset.csv', overwrite=True, show_progress=True)\n",
    "paths=[(ds, 'dataset.csv')]\n",
    "path='https://raw.githubusercontent.com/sonalgan/DeepLearning/master/dataset.csv'\n",
    "lang_ds = Dataset.Tabular.from_delimited_files(path=path)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "#weather_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='./src', target_path='langdataset.csv', overwrite=True, show_progress=True)\n",
    "\n",
    "lang_ds.take(3).to_pandas_dataframe()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>ਰੋਗਾਣੂ</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>ਸਰਜਨ</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>ਟਾਇਰਾਂ</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>ਪੀਐੱਮਜੀਕੇਪੀ</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>ਰੁੱਝੀ</td>\n",
       "      <td>pa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words lang\n",
       "99995       ਰੋਗਾਣੂ   pa\n",
       "99996         ਸਰਜਨ   pa\n",
       "99997       ਟਾਇਰਾਂ   pa\n",
       "99998  ਪੀਐੱਮਜੀਕੇਪੀ   pa\n",
       "99999        ਰੁੱਝੀ   pa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = lang_ds.to_pandas_dataframe()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>तुम</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>हम</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>रूप</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>लोगों</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>मैं</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words lang\n",
       "0    तुम   hi\n",
       "1     हम   hi\n",
       "2    रूप   hi\n",
       "3  लोगों   hi\n",
       "4    मैं   hi"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./dataset.csv',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_ds = lang_ds.register(workspace=ws,\n",
    " #                                name='lang_ds',\n",
    "  #                               description='language training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"AzureMLFramework\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D16s_v3',\n",
    "                                                           max_nodes=4,\n",
    "                                                          vm_priority='dedicated')\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dlenv.yml'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "fwrk = Environment(\"dlenv\")\n",
    "\n",
    "fwrk.docker.enabled = True\n",
    "fwrk.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn',\n",
    "                                                                          'pandas',\n",
    "                                                                          'numpy',\n",
    "                                                                          'tensorflow==1.15',\n",
    "                                                                          'keras'\n",
    "                            \n",
    "                                                                         ])\n",
    "\n",
    "fwrk.python.conda_dependencies.add_pip_package(\"inference-schema[numpy-support]\")\n",
    "fwrk.python.conda_dependencies.add_pip_package('joblib')\n",
    "fwrk.python.conda_dependencies.add_pip_package('wget')\n",
    "fwrk.python.conda_dependencies.save_to_file(\".\", \"dlenv.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Submit the Training Job to the Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "lang_ds=Dataset.get_by_name(workspace=ws, name='lang_ds')\n",
    "args=['--input-data', lang_ds.as_named_input('lang'),\n",
    "'--batch-size',1024,\n",
    "'--test-size',0.3,\n",
    "'--first-layer-neurons',600,\n",
    "'--second-layer-neurons',400,\n",
    "'--third-layer-neurons',200,\n",
    "'--fourth-layer-neurons',0,\n",
    "'--learning-rate',0.001,\n",
    "'--dropout1',0.5,\n",
    "'--dropout2',0,\n",
    "'--dropout3',0,\n",
    "'--weight-constraint',4]\n",
    "\n",
    "src = ScriptRunConfig(source_directory=script_folder, script='./train.py',\n",
    "                      arguments=args\n",
    "                     )\n",
    "\n",
    "# Set compute target to the one created in previous step\n",
    "src.run_config.target = cpu_cluster.name\n",
    "\n",
    "# Set environment\n",
    "src.run_config.environment = fwrk\n",
    " \n",
    "#run = exp.submit(config=src)\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: langdetection_1613505605_6fe92740\n",
      "Web View: https://ml.azure.com/experiments/langdetection/runs/langdetection_1613505605_6fe92740?wsid=/subscriptions/d7b4badf-6888-4e39-b572-64a569d1930a/resourcegroups/rghpe/workspaces/mlhpe2\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-02-16T20:03:31Z Starting output-watcher...\n",
      "2021-02-16T20:03:31Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-02-16T20:03:32Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-02-16T20:03:32Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_2c82a7ea0909b66d46f5eb0620b4f0f0\n",
      "be8ec4e48d7f: Pulling fs layer\n",
      "33b8b485aff0: Pulling fs layer\n",
      "d887158cc58c: Pulling fs layer\n",
      "05895bb28c18: Pulling fs layer\n",
      "baf7ab26f516: Pulling fs layer\n",
      "181182e3c9cf: Pulling fs layer\n",
      "d584ef274e55: Pulling fs layer\n",
      "baf7ab26f516: Waiting\n",
      "05895bb28c18: Waiting\n",
      "181182e3c9cf: Waiting\n",
      "c445dda55407: Pulling fs layer\n",
      "699b75ff4717: Pulling fs layer\n",
      "b177109c9d16: Pulling fs layer\n",
      "59cea07bb66c: Pulling fs layer\n",
      "d54d011de0e3: Pulling fs layer\n",
      "d584ef274e55: Waiting\n",
      "59cea07bb66c: Waiting\n",
      "d54d011de0e3: Waiting\n",
      "b177109c9d16: Waiting\n",
      "dfcf8b6eed60: Pulling fs layer\n",
      "07ed34af3fc0: Pulling fs layer\n",
      "a46d4abd4c9e: Pulling fs layer\n",
      "9035501e640a: Pulling fs layer\n",
      "e3a3698ea293: Pulling fs layer\n",
      "f51783951748: Pulling fs layer\n",
      "a46d4abd4c9e: Waiting\n",
      "9035501e640a: Waiting\n",
      "e3a3698ea293: Waiting\n",
      "f51783951748: Waiting\n",
      "dfcf8b6eed60: Waiting\n",
      "07ed34af3fc0: Waiting\n",
      "699b75ff4717: Waiting\n",
      "d887158cc58c: Verifying Checksum\n",
      "d887158cc58c: Download complete\n",
      "33b8b485aff0: Verifying Checksum\n",
      "33b8b485aff0: Download complete\n",
      "05895bb28c18: Verifying Checksum\n",
      "05895bb28c18: Download complete\n",
      "be8ec4e48d7f: Verifying Checksum\n",
      "be8ec4e48d7f: Download complete\n",
      "181182e3c9cf: Verifying Checksum\n",
      "181182e3c9cf: Download complete\n",
      "d584ef274e55: Verifying Checksum\n",
      "d584ef274e55: Download complete\n",
      "baf7ab26f516: Verifying Checksum\n",
      "baf7ab26f516: Download complete\n",
      "b177109c9d16: Download complete\n",
      "be8ec4e48d7f: Pull complete\n",
      "59cea07bb66c: Verifying Checksum\n",
      "59cea07bb66c: Download complete\n",
      "33b8b485aff0: Pull complete\n",
      "d887158cc58c: Pull complete\n",
      "c445dda55407: Verifying Checksum\n",
      "c445dda55407: Download complete\n",
      "05895bb28c18: Pull complete\n",
      "d54d011de0e3: Download complete\n",
      "dfcf8b6eed60: Verifying Checksum\n",
      "dfcf8b6eed60: Download complete\n",
      "699b75ff4717: Verifying Checksum\n",
      "699b75ff4717: Download complete\n",
      "07ed34af3fc0: Verifying Checksum\n",
      "07ed34af3fc0: Download complete\n",
      "a46d4abd4c9e: Download complete\n",
      "9035501e640a: Download complete\n",
      "f51783951748: Verifying Checksum\n",
      "f51783951748: Download complete\n",
      "baf7ab26f516: Pull complete\n",
      "181182e3c9cf: Pull complete\n",
      "d584ef274e55: Pull complete\n",
      "c445dda55407: Pull complete\n",
      "e3a3698ea293: Verifying Checksum\n",
      "e3a3698ea293: Download complete\n",
      "699b75ff4717: Pull complete\n",
      "b177109c9d16: Pull complete\n",
      "59cea07bb66c: Pull complete\n",
      "d54d011de0e3: Pull complete\n",
      "dfcf8b6eed60: Pull complete\n",
      "07ed34af3fc0: Pull complete\n",
      "a46d4abd4c9e: Pull complete\n",
      "9035501e640a: Pull complete\n",
      "e3a3698ea293: Pull complete\n",
      "f51783951748: Pull complete\n",
      "Digest: sha256:5dd67426a04dc81a332b18339dc22eba381957dcc3f7b93bef0a8e09eb0bd4ca\n",
      "Status: Downloaded newer image for a76bcddef28a4f1abc588e4869b9b0b9.azurecr.io/azureml/azureml_2c82a7ea0909b66d46f5eb0620b4f0f0:latest\n",
      "a76bcddef28a4f1abc588e4869b9b0b9.azurecr.io/azureml/azureml_2c82a7ea0909b66d46f5eb0620b4f0f0:latest\n",
      "2021-02-16T20:04:10Z Check if container langdetection_1613505605_6fe92740 already exist exited with 0, \n",
      "\n",
      "9bd44eb9401f09c353d4499c23dedbc297a6b7da9f9d1cd8422e9ec04134a68a\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "2021/02/16 20:04:32 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/02/16 20:04:32 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2021-02-16T20:04:34.046203] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--input-data', '49ff27a4-f9ee-4189-bb01-61ec40da3d9d', '--batch-size', '1024', '--first-layer-neurons', '600', '--second-layer-neurons', '400', '--third-layer-neurons', '200', '--fourth-layer-neurons', '0', '--learning-rate', '0.001', '--dropout1', '0.5', '--dropout2', '0', '--dropout3', '0', '--weight-constraint', '4'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 105\n",
      "[2021-02-16T20:04:36.560691] Entering Run History Context Manager.\n",
      "[2021-02-16T20:04:37.300863] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mlhpe2/azureml/langdetection_1613505605_6fe92740/mounts/workspaceblobstore/azureml/langdetection_1613505605_6fe92740\n",
      "[2021-02-16T20:04:37.307856] Preparing to call script [train.py] with arguments:['--input-data', '49ff27a4-f9ee-4189-bb01-61ec40da3d9d', '--batch-size', '1024', '--first-layer-neurons', '600', '--second-layer-neurons', '400', '--third-layer-neurons', '200', '--fourth-layer-neurons', '0', '--learning-rate', '0.001', '--dropout1', '0.5', '--dropout2', '0', '--dropout3', '0', '--weight-constraint', '4']\n",
      "[2021-02-16T20:04:37.307979] After variable expansion, calling script [train.py] with arguments:['--input-data', '49ff27a4-f9ee-4189-bb01-61ec40da3d9d', '--batch-size', '1024', '--first-layer-neurons', '600', '--second-layer-neurons', '400', '--third-layer-neurons', '200', '--fourth-layer-neurons', '0', '--learning-rate', '0.001', '--dropout1', '0.5', '--dropout2', '0', '--dropout3', '0', '--weight-constraint', '4']\n",
      "\n",
      "Using TensorFlow backend.\n",
      "(70000, 32, 23)\n",
      "(30000, 32, 23)\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_297cacdba110e9eae7fd2bce576b72ce/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_297cacdba110e9eae7fd2bce576b72ce/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2021-02-16 20:05:04.325975: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-16 20:05:04.352607: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2593905000 Hz\n",
      "2021-02-16 20:05:04.352923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5628770e0d70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-16 20:05:04.353005: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3\n",
      "OMP: Info #214: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #156: KMP_AFFINITY: 4 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #285: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #285: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "OMP: Info #285: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"core\".\n",
      "OMP: Info #285: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"core\".\n",
      "OMP: Info #285: KMP_AFFINITY: topology layer \"thread\" is equivalent to \"core\".\n",
      "OMP: Info #191: KMP_AFFINITY: 1 socket x 4 cores/socket x 1 thread/core (4 total cores)\n",
      "OMP: Info #216: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to socket 0 core 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to socket 0 core 2 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to socket 0 core 3 \n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 105 thread 0 bound to OS proc set 0\n",
      "2021-02-16 20:05:04.353954: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_297cacdba110e9eae7fd2bce576b72ce/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 308 thread 1 bound to OS proc set 1\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 310 thread 2 bound to OS proc set 2\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 311 thread 3 bound to OS proc set 3\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 312 thread 4 bound to OS proc set 0\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 307 thread 5 bound to OS proc set 1\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 314 thread 7 bound to OS proc set 3\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 313 thread 6 bound to OS proc set 2\n",
      "OMP: Info #252: KMP_AFFINITY: pid 105 tid 315 thread 8 bound to OS proc set 0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-02-16T20:19:39.023458] Entering job release\n",
      "[2021-02-16T20:19:40.020810] Starting job release\n",
      "[2021-02-16T20:19:40.021465] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 470\n",
      "[2021-02-16T20:19:40.021686] job release stage : upload_datastore starting...\n",
      "[2021-02-16T20:19:40.022370] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-02-16T20:19:40.022407] job release stage : execute_job_release starting...\n",
      "[2021-02-16T20:19:40.022949] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-02-16T20:19:40.023017] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-02-16T20:19:40.038384] Entering context manager injector.\n",
      "[2021-02-16T20:19:40.040858] job release stage : upload_datastore completed...\n",
      "[2021-02-16T20:19:40.284392] job release stage : execute_job_release completed...\n",
      "[2021-02-16T20:19:40.385287] job release stage : send_run_telemetry starting...\n",
      "[2021-02-16T20:19:40.637100] get vm size and vm region successfully.\n",
      "[2021-02-16T20:19:41.116618] get compute meta data successfully.\n",
      "[2021-02-16T20:19:41.424392] post artifact meta request successfully.\n",
      "[2021-02-16T20:19:41.464188] upload compute record artifact successfully.\n",
      "[2021-02-16T20:19:41.627296] job release stage : send_run_telemetry completed...\n",
      "[2021-02-16T20:19:41.627531] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: langdetection_1613505605_6fe92740\n",
      "Web View: https://ml.azure.com/experiments/langdetection/runs/langdetection_1613505605_6fe92740?wsid=/subscriptions/d7b4badf-6888-4e39-b572-64a569d1930a/resourcegroups/rghpe/workspaces/mlhpe2\n",
      "\n",
      "CPU times: user 1.34 s, sys: 155 ms, total: 1.49 s\n",
      "Wall time: 19min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'langdetection_1613505605_6fe92740',\n",
       " 'target': 'AzureMLFramework',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-02-16T20:03:26.45396Z',\n",
       " 'endTimeUtc': '2021-02-16T20:19:53.79707Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'dea61172-052b-4fab-be68-ffe1faece4ec',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '49ff27a4-f9ee-4189-bb01-61ec40da3d9d'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'lang', 'mechanism': 'Direct'}}, {'dataset': {'id': '49ff27a4-f9ee-4189-bb01-61ec40da3d9d'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data',\n",
       "   'DatasetConsumptionConfig:lang',\n",
       "   '--batch-size',\n",
       "   '1024',\n",
       "   '--first-layer-neurons',\n",
       "   '600',\n",
       "   '--second-layer-neurons',\n",
       "   '400',\n",
       "   '--third-layer-neurons',\n",
       "   '200',\n",
       "   '--fourth-layer-neurons',\n",
       "   '0',\n",
       "   '--learning-rate',\n",
       "   '0.001',\n",
       "   '--dropout1',\n",
       "   '0.5',\n",
       "   '--dropout2',\n",
       "   '0',\n",
       "   '--dropout3',\n",
       "   '0',\n",
       "   '--weight-constraint',\n",
       "   '4'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'AzureMLFramework',\n",
       "  'dataReferences': {},\n",
       "  'data': {'lang': {'dataLocation': {'dataset': {'id': '49ff27a4-f9ee-4189-bb01-61ec40da3d9d',\n",
       "      'name': 'lang_ds',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'lang',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'dlenv',\n",
       "   'version': 'Autosave_2021-02-16T03:18:41Z_b62ec231',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.20.0',\n",
       "        'inference-schema[numpy-support]',\n",
       "        'joblib',\n",
       "        'wget']},\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'tensorflow==1.15',\n",
       "      'keras'],\n",
       "     'name': 'azureml_297cacdba110e9eae7fd2bce576b72ce'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': None, 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/azureml-logs/55_azureml-execution-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt?sv=2019-02-02&sr=b&sig=3kxHXTzj714ivvAK8kDgrWIyYA90hEYRT8D2CEwis2A%3D&st=2021-02-16T20%3A10%3A28Z&se=2021-02-17T04%3A20%3A28Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/azureml-logs/65_job_prep-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt?sv=2019-02-02&sr=b&sig=FxIKSlVWRFskQRMGIMY48FIFt5vbBhLqJX774Fyjal4%3D&st=2021-02-16T20%3A10%3A28Z&se=2021-02-17T04%3A20%3A28Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=YnwHM3v9ps5N9Qz89ycm1p1NHqYFhbNMw8QAOwrDvp4%3D&st=2021-02-16T20%3A10%3A28Z&se=2021-02-17T04%3A20%3A28Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/azureml-logs/75_job_post-tvmps_86cb858287b5197ebfa49706895cede08ca6e472e8a1e8d9c457150adaad11ae_d.txt?sv=2019-02-02&sr=b&sig=MqWywwal7mhMwNjT41yr%2Fcxlv0VyAot%2Bmp6kXi5%2F5zs%3D&st=2021-02-16T20%3A10%3A28Z&se=2021-02-17T04%3A20%3A28Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=UVPbF0fDEG3LGp673UAPoIGpfnuyvL%2FbXlE9baztBr8%3D&st=2021-02-16T20%3A10%3A28Z&se=2021-02-17T04%3A20%3A28Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=noUyYudDpsp3u8K%2BCcVKcJ8x876%2FQ5uDGEnPV6ajZvY%3D&st=2021-02-16T20%3A10%3A28Z&se=2021-02-17T04%3A20%3A28Z&sp=r',\n",
       "  'logs/azureml/105_azureml.log': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/105_azureml.log?sv=2019-02-02&sr=b&sig=dVIvWH32FuOEzS0qQ0nFc8M252i7Qrp4yrgu4clGs9E%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=%2BaFCyHFvn3hhc%2B9DIw68Ux7egfkcochOusLfmjmFbFU%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Lt8BuStPq7g%2FB5FjQBz8vP3dxQ6okBKEUPcadvGzZQ0%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r',\n",
       "  'logs/azureml/dataprep/engine_spans_l_8a37defc-5e6c-4870-8edf-7e68dcd04936.jsonl': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/dataprep/engine_spans_l_8a37defc-5e6c-4870-8edf-7e68dcd04936.jsonl?sv=2019-02-02&sr=b&sig=J4%2BrlpSvbi8X9if02uz%2BaL7Q%2BQGFY%2FHJEunki1kkD%2BA%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r',\n",
       "  'logs/azureml/dataprep/python_span_l_8a37defc-5e6c-4870-8edf-7e68dcd04936.jsonl': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/dataprep/python_span_l_8a37defc-5e6c-4870-8edf-7e68dcd04936.jsonl?sv=2019-02-02&sr=b&sig=zhWj8HoAhbVL41dtu6WiHEIWbg4gnguaR2bZPzG74MM%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=iB5MaOvWdgg%2FfhNkDACw6qMUzG5aniCoB8WXtO8sLuU%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mlhpe26304449420.blob.core.windows.net/azureml/ExperimentRun/dcid.langdetection_1613505605_6fe92740/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=wQp8I%2F2Q8B9IIqDlhKhbsdwXGrGdih0QeVXjFqmq%2FcE%3D&st=2021-02-16T20%3A10%3A27Z&se=2021-02-17T04%3A20%3A27Z&sp=r'},\n",
       " 'submittedBy': 'Sonal Ganvir'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\tmodel:1\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33279, st_ino=18014505162109878272, st_dev=46, st_nlink=1, st_uid=0, st_gid=0, st_size=9189325, st_atime=1613512727, st_mtime=1613512727, st_ctime=1613512727)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run.register_model(model_name='model', model_path='./outputs/model.pkl')\n",
    "print(model.name, model.id, model.version, sep='\\t')\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "import os \n",
    "ws = Workspace.from_config()\n",
    "model=Model(ws, 'model')\n",
    "\n",
    "model.download(target_dir=os.getcwd(), exist_ok=True)\n",
    "\n",
    "# verify the downloaded model file\n",
    "file_path = os.path.join(os.getcwd(), \"./model.pkl\")\n",
    "\n",
    "os.stat(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Sampling the hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import BayesianParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import choice, loguniform, quniform,uniform\n",
    "\n",
    "ps =BayesianParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(32, 64, 128,256,512,1024),\n",
    "        '--test-size':choice(0.10,0.15,0.20),\n",
    "        '--first-layer-neurons': choice( 600, 650, 700),\n",
    "        '--second-layer-neurons': choice( 400, 450, 500),\n",
    "        '--third-layer-neurons': choice(200,250,300),\n",
    "        '--fourth-layer-neurons': choice(0,50,100),\n",
    "        '--learning-rate': uniform(0.000001,0.1),\n",
    "        '--dropout1': choice(0.5,0.6,0.7,0.8),\n",
    "        '--dropout2': choice(0,0.2,0.3,0.4,0.5),\n",
    "        '--dropout3':choice(0,0.2,0.3,0.4,0.5),\n",
    "        '--weight-constraint':choice(1,2,3,4)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create Config scipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ['--input-data', lang_ds.as_named_input('lang')]\n",
    "\n",
    "src = ScriptRunConfig(source_directory=script_folder, script='./train.py',\n",
    "                      arguments=args\n",
    "                     )\n",
    "src.run_config.target = cpu_cluster.name\n",
    "src.run_config.environment = fwrk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Define Termination policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Specify primary metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
    "                                     hyperparameter_sampling=ps,\n",
    "                                     primary_metric_name='Loss',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                                     max_total_runs=220,\n",
    "                                     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Submit the Hypertuning job to the compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = exp.submit(config=hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_7b4b5b93-ec8b-4e19-8bf4-80517e27f2ba\n",
      "Web View: https://ml.azure.com/experiments/langdetection/runs/HD_7b4b5b93-ec8b-4e19-8bf4-80517e27f2ba?wsid=/subscriptions/d7b4badf-6888-4e39-b572-64a569d1930a/resourcegroups/rghpe/workspaces/mlhpe2\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2021-02-17T02:26:23.761099][API][INFO]Experiment created<END>\\n\"\"<START>[2021-02-17T02:26:24.853706][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\"<START>[2021-02-17T02:26:24.490354][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"<START>[2021-02-17T02:26:25.0606848Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n"
     ]
    }
   ],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--input-data', 'DatasetConsumptionConfig:lang', '--batch-size', '512', '--dropout1', '0.7', '--dropout2', '0.7', '--dropout3', '0.5', '--first-layer-neurons', '350', '--fourth-layer-neurons', '400', '--learning-rate', '0.002537527700592502', '--second-layer-neurons', '600', '--test-size', '0.1', '--third-layer-neurons', '500', '--weight-constraint', '4']\n"
     ]
    }
   ],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/55_azureml-execution-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/65_job_prep-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/107_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/engine_spans_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/dataprep/python_span_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.pkl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(best_run.get_file_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelPathNotFoundException",
     "evalue": "ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path outputs/model in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/65_job_prep-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/107_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/engine_spans_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/dataprep/python_span_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.pkl']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path outputs/model in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/65_job_prep-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/107_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/engine_spans_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/dataprep/python_span_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.pkl']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelPathNotFoundException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0388b8a50ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'langmodel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outputs/model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, description, datasets, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m   2107\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2109\u001b[0;31m             sample_output_dataset=sample_output_dataset, resource_configuration=resource_configuration, **kwargs)\n\u001b[0m\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_dataset_lineage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_run_impl/run_history_facade.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, asset_id, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m             raise ModelPathNotFoundException(\n\u001b[1;32m    436\u001b[0m                 \"\"\"Could not locate the provided model_path {} in the set of files uploaded to the run: {}\n\u001b[0;32m--> 437\u001b[0;31m                 See https://aka.ms/run-logging for more details.\"\"\".format(model_path, str(run_files)))\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"prefix\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0martifact_prefix_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mmetadata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelPathNotFoundException\u001b[0m: ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path outputs/model in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/65_job_prep-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/107_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/engine_spans_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/dataprep/python_span_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.pkl']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path outputs/model in the set of files uploaded to the run: ['azureml-logs/55_azureml-execution-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/65_job_prep-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_36cd85af4a51758a4dc2c981f4ecdb1aa5b31c1e9d1307483a4dd9402216a9b6_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/107_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/engine_spans_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/dataprep/python_span_l_56145ac0-043b-465f-a017-798a7d3737d3.jsonl', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/model.pkl']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "model = best_run.register_model(model_name='langmodel', model_path='./outputs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
